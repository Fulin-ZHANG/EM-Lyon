{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"images/emlyon.png\" style=\"height:60px; float:left; padding-right:10px; margin-top:5px\" />\n",
    "    <span>\n",
    "        <h1 style=\"padding-bottom:5px;\"> Introduction to Deep Learning </h1>\n",
    "        <a href=\"https://masters.em-lyon.com/fr/msc-in-data-science-artificial-intelligence-strategy\">[DSAIS]</a> MSc in Data Science & Artificial Intelligence Strategy <br/>\n",
    "         Paris | © Saeed VARASTEH\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 07 : First RNN Model\n",
    "\n",
    "In this notebook, we will build our first RNN model and try to understand its mechanics. We will heavily use the content from our third lecture (notebook) in the model training section.\n",
    "\n",
    "<img style=\"width:60%\" src=\"./images/rnn_unrolled.png\" />\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "np.random.seed(72)\n",
    "torch.manual_seed(72)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation\n",
    "\n",
    "Let’s start generating some synthetic data: we start with a vector of 1000 points from the __sine__ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "series = np.sin(0.1*np.arange(N)) + np.random.randn(N)*0.1\n",
    "\n",
    "plt.plot(series)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see if we can use __L__ past values to predict the next value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 10\n",
    "X = []\n",
    "y = []\n",
    "for t in range(len(series) - L):\n",
    "    x_ = series[t:t+L]\n",
    "    X.append(x_)\n",
    "    y_ = series[t+L]\n",
    "    y.append(y_)\n",
    "\n",
    "X = np.array(X).reshape(-1, L, 1)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "N = len(X)\n",
    "print(\"X.shape\", X.shape, \"Y.shape\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let’s split our synthetic data into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X[:-N//2].astype(np.float32))\n",
    "y_train = torch.from_numpy(y[:-N//2].astype(np.float32))\n",
    "X_test = torch.from_numpy(X[-N//2:].astype(np.float32))\n",
    "y_test = torch.from_numpy(y[-N//2:].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model\n",
    "\n",
    "Let’s build a proper (yet simple) RNN model for this regression task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size = 1, hidden_size = 5, num_layers = 1, batch_first=True)\n",
    "        self.fc = nn.Linear(5, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # initial hidden states\n",
    "        h0 = torch.zeros(1, x.size(0), 5).to(device) # nb of layers, batch_size, number of hidden units \n",
    "        \n",
    "        out, _ = self.rnn(x, h0)\n",
    "        \n",
    "        # out is of size (batch size, sequence length, nb of hidden units)\n",
    "        # we only want the out at the final time step\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding RNN Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN()\n",
    "\n",
    "inputs = X_train[:16]\n",
    "\n",
    "outputs = model(inputs)\n",
    "\n",
    "inputs.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN().to(device)\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 200\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    x_batch = X_train.to(device) \n",
    "    y_batch = y_train.to(device)\n",
    "    \n",
    "    yhat = model(x_batch)\n",
    "    loss = loss_fn(yhat, y_batch)\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "                        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{n_epochs}, Train Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses,  label=\"train loss\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model( X_test.to(device) )\n",
    "y_pred = y_pred.detach().numpy()\n",
    "\n",
    "plt.plot(y_test[:], c=\"b\", label=\"actual data\");\n",
    "plt.plot(y_pred[:], c=\"r\", label=\"predicted data\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
