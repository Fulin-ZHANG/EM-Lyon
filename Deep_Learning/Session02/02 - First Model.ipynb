{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"../images/emlyon.png\" style=\"height:60px; float:left; padding-right:10px; margin-top:5px\" />\n",
    "    <span>\n",
    "        <h1 style=\"padding-bottom:5px;\"> Introduction to Deep Learning </h1>\n",
    "        <a href=\"https://masters.em-lyon.com/fr/msc-in-data-science-artificial-intelligence-strategy\">[DSAIS]</a> MSc in Data Science & Artificial Intelligence Strategy <br/>\n",
    "         Paris | © Saeed VARASTEH\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 02 : First Model\n",
    "\n",
    "In this lecture, we will see the main reasons why PyTorch makes it much easier and more intuitive to build a Deep Learning model in Python.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Regression Problem\n",
    "\n",
    "Let's consider a simple and familiar problem: a linear regression with a single feature __x__!\n",
    "\n",
    "$$ y = a * x + b $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation\n",
    "\n",
    "Let’s start generating some synthetic data: we start with a vector of 100 points for our feature __x__.\n",
    "\n",
    "Next, let’s split our synthetic data into train and test sets, shuffling the array of indices and using the first 80 shuffled points for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Generation\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2 * X + 1. + .1 * np.random.randn(100, 1)\n",
    "\n",
    "# Shuffles the indices\n",
    "idx = np.arange(100)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Uses first 80 random indices for train\n",
    "train_idx = idx[:80]\n",
    "# Uses the remaining indices for validation\n",
    "test_idx = idx[80:]\n",
    "\n",
    "# Generates train and test sets\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "# Visualize data\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "ax[0].scatter(X_train,y_train, c=\"b\", label=\"train data\"); ax[0].legend();\n",
    "ax[1].scatter(X_test,y_test, c=\"r\", label=\"test data\"); ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "We know that a = 2 and b = 1, but now let’s see how close we can get to the true values by using <b>gradient descent</b> and the 80 points in the training set.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "\n",
    "For a regression problem, the loss is given by the Mean Square Error (MSE), that is, the average of all squared differences between actual labels ($y$) and the model predictions ($\\hat{y} = h_{\\theta}(\\boldsymbol{x})$). The goal is to minimize the loss value.\n",
    "\n",
    "$$ \\mathcal{L} = \\frac{1}{2 m} \\sum_{i=1}^m (\\hat{y^i} - y^i)^2 = \\frac{1}{2 m} \\sum_{i=1}^m (ax^i + b - y^i)^2 $$\n",
    "\n",
    "To change the value of this loss, we need to change the model parameters; i.e. __a__ and __b__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent: Update Rule\n",
    "\n",
    "We use the gradients to update the parameters. Since we are trying to minimize our losses, we reverse the sign of the gradient for the update.\n",
    "\n",
    "$$ a = a - \\eta \\frac{\\partial \\mathcal{L} } {\\partial a} $$\n",
    "$$ b = b - \\eta \\frac{\\partial \\mathcal{L} } {\\partial b} $$\n",
    "\n",
    "There is still another parameter (hyperparameter) to consider: __the learning rate__, denoted by the Greek letter __eta__ ($\\eta$), which is the multiplicative factor that we need to apply to the gradient for the parameter update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent: The Gradients\n",
    "\n",
    "A gradient is a partial derivative — why partial? Because one computes it with respect to (w.r.t.) a single parameter. We have two parameters, __a__ and __b__, so we must compute two partial derivatives.\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial \\mathcal{L} } {\\partial a} = \\frac{1}{m} \\sum_{i=1}^m x^i (\\hat{y^i}-y^i)^2  $$\n",
    "$$ \\frac{\\partial \\mathcal{L} } {\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y^i}-y^i)^2  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression in Numpy\n",
    "\n",
    "Let's first using Numpy only. Then, you can fully appreciate how much PyTorch makes your life easier!\n",
    "\n",
    "The initialization steps:\n",
    "\n",
    "- Random initialization of parameters/weights (we have only two, a and b);\n",
    "- Initialization of hyper-parameters (in our case, only learning rate and number of epochs);\n",
    "\n",
    "The training steps:\n",
    "\n",
    "- Compute model’s predictions — this is the forward pass.\n",
    "- Compute the loss, using predictions and and labels and the appropriate loss function for the task at hand.\n",
    "- Compute the gradients for every parameter.\n",
    "- Update the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.02514259] [0.18645431]\n"
     ]
    }
   ],
   "source": [
    "# Initializes parameters \"a\" and \"b\" randomly\n",
    "a = np.random.randn(1)\n",
    "b = np.random.randn(1)\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.96752391] [1.02427697]\n"
     ]
    }
   ],
   "source": [
    "# Sets learning rate\n",
    "lr = 1e-1\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Computes our model's predicted output\n",
    "    yhat = a * X_train + b \n",
    "    \n",
    "    # How wrong is our model? That's the error! \n",
    "    error = yhat - y_train\n",
    "    # It is a regression, so it computes mean squared error (MSE)\n",
    "    loss = 0.5 * (error ** 2).mean()\n",
    "    \n",
    "    # Computes gradients for both \"a\" and \"b\" parameters\n",
    "    a_grad = (X_train * error).mean()\n",
    "    b_grad = error.mean()\n",
    "    \n",
    "    # Updates parameters using gradients and the learning rate\n",
    "    a = a - lr * a_grad\n",
    "    b = b - lr * b_grad\n",
    "    \n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure we haven’t done any mistakes in our code, we can use Scikit-Learn’s Linear Regression to fit the model and compare the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.96896447] [1.02354075]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linr = LinearRegression()\n",
    "linr.fit(X_train, y_train)\n",
    "print(linr.coef_[0], linr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do it in PyTorch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchviz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_dot\n\u001b[1;32m      6\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchviz'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data\n",
    "\n",
    "How do we go from Numpy’s arrays to PyTorch’s tensors?\n",
    "\n",
    "Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors and and then we send them to the chosen device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "\n",
    "How do we make a tensor a (trainable) parameter/weight?\n",
    "\n",
    "The tensors require the computation of its gradients, so we can update their values (the parameters’ values. \n",
    "\n",
    "That’s what the `requires_grad=True` argument is good for. It tells PyTorch we want it to compute gradients for this tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m yhat \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m*\u001b[39m X_train_tensor \u001b[38;5;241m+\u001b[39m b\n\u001b[1;32m      2\u001b[0m error \u001b[38;5;241m=\u001b[39m yhat \u001b[38;5;241m-\u001b[39m y_train_tensor\n\u001b[1;32m      3\u001b[0m loss \u001b[38;5;241m=\u001b[39m (error \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "yhat = a * X_train_tensor + b\n",
    "error = yhat - y_train_tensor\n",
    "loss = (error ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_dot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m make_dot(yhat)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_dot' is not defined"
     ]
    }
   ],
   "source": [
    "make_dot(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __blue boxes__: these correspond to the tensors we use as parameters, the ones we’re asking PyTorch to compute gradients for;\n",
    "- __gray box__: a Python operation that involves a gradient-computing tensor or its dependencies;\n",
    "- __green box__: the same as the gray box, except it is the starting point for the computation of gradients (assuming the `backward()` method is called from the variable used to visualize the graph)— they are computed from the bottom-up in a graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "If we plot graphs for the error (center) and loss (right) variables, the only difference between them and the first one is the number of intermediate steps (gray boxes).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why don’t we have a box for our data __x__? The answer is: we do not compute gradients for it! So, even though there are more tensors involved in the operations performed by the computation graph, it only shows gradient-computing tensors and its dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer\n",
    "\n",
    "An optimizer takes the parameters we want to update, the learning rate we want to use (and possibly many other hyper-parameters as well!) and performs the updates through its `step()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we create a Stochastic Gradient Descent (SGD) optimizer to update our parameters __a__ and __b__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD([a, b], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a * X_train_tensor + b\n",
    "    error = yhat - y_train_tensor\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    optimizer.zero_grad() # Telling PyTorch to let gradients go!\n",
    "\n",
    "    loss.backward() # It computes all gradients for all learnable parameters\n",
    "    \n",
    "    optimizer.step() # To update the parameters\n",
    "    \n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    <b>Autograd</b> is PyTorch’s automatic differentiation package. Thanks to it, we don’t need to worry about partial derivatives, chain rule or anything like it. It means it computes all gradients for you. How? That’s what <code>backward()</code> is good for.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-danger\">\n",
    "Before computing the gradients you have to zero out gradients - Why? Because by default the gradients are accumulated. That is what <code>optimizer.zero_grad()</code> is good for.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Loss\n",
    "\n",
    "We now tackle the loss computation. As expected, PyTorch got us covered once again. There are many loss functions to choose from, depending on the task at hand. Since ours is a regression, we are using the Mean Square Error (MSE) loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PyTorch MSE loss, our code will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "optimizer = optim.SGD([a, b], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a * X_train_tensor + b\n",
    "    \n",
    "    loss = loss_fn(yhat, y_train_tensor) # No more manual loss!\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    \n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-warning\">\n",
    "Notice that nn.MSELoss actually creates a loss function for us — it is NOT the loss function itself. Moreover, you can specify a reduction method to be applied, that is, how do you want to aggregate the results for individual points — you can average them (reduction=’mean’) or simply sum them up (reduction=’sum’).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Linear Module\n",
    "\n",
    "We compute the predicted output ourselves. Let’s use PyTorch Linear Module instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Now we can create a Linear module and use it to compute the output\n",
    "# Instead of our custom parameters, we use a Linear layer with single input and single output\n",
    "model = nn.Linear(1, 1) # in_features, out_features, \n",
    "# We can also inspect its parameters using its state_dict()\n",
    "print(model.state_dict())\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = model(X_train_tensor) # No more manual prediction!\n",
    "    \n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()  # To calculate the gradients  \n",
    "    optimizer.step()   # To update the model weights\n",
    "    \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, The PyTorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "    In PyTorch, a model is represented by a regular Python class that inherits from the <b>Module</b> class.\n",
    "</div>\n",
    "\n",
    "The most fundamental methods it needs to implement are:\n",
    "\n",
    "- `__init__(self)`: it defines the parts that make up the model —in our case, the `nn.Linear` module.\n",
    "- `forward(self, x)`: it performs the actual computation, that is, it outputs a prediction, given the input __x__.\n",
    "\n",
    "__Note:__ You should NOT call the `forward(x)` method, though. You should call the whole model itself, as in `model(x)` to perform a forward pass and output predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s build a proper (yet simple) model for our regression task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize Linear Regression Class\n",
    "class MyModel(nn.Module):\n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "    \n",
    "    # Prediction function\n",
    "    def forward(self, x):\n",
    "        # Computes the outputs / predictions\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = MyModel().to(device)\n",
    "\n",
    "print(model.state_dict())\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train() # What is this?\n",
    "\n",
    "    yhat = model(X_train_tensor)\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-danger\">\n",
    "    <b><span style='color:red'>IMPORTANT</span>: we need to send our model to the same device where the data is. If our data is made of GPU tensors, our model must “live” inside the GPU as well.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    Moreover, we can get the current values for all parameters using our model’s <b>state_dict()</b> method.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "The only purpose of <b>model.train()</b> is to set the model to training mode. Why is this important? Some models may use mechanisms like Dropout, for instance, which have distinct behaviors in training and evaluation phases.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "In PyTorch, every method that ends with an underscore (_) makes changes in-place, meaning, they will modify the underlying variable\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
